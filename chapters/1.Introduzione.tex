\section{Introduzione}

L'obiettivo di questo breve progetto è quello di riprodurre un \textbf{Distributed Adaptive Controller} per Agenti Robotici, descritto in \cite{pfeifer2001understanding} e \cite{verschure1992distributed}, che permetta di \textit{apprendere in maniera completamente autonoma e non supervisionata} il comportamento della Obstacle-Avoidance, sfruttando una semplice Artificial Neural Network di tipo Feed-Forward.

Nella fattispecie si vuole studiare come il modello di controller riprodotto è influenzato dalla presenza di un numero variabile di sensori e dalla loro posizione. Nel corso della relazione verranno descritti 3 modelli di agente robotico, ognuno dei quali si distingue per una diversa configurazione neurale.

Gli agenti robotici adoperati nel corso dell'esperimento sono totalmente simulati e sono stati realizzati tramite l'ausilio dell'ambiente virtuale di Webots (R2019a revision 1) \cite{michel2004cyberbotics}.

Nella sezione iniziale verrà illustrata brevemente la struttura dei robot adoperati sia dal punto di vista della loro morfologia e dei sensori equipaggiati che da quello della struttura della rete neurale che ne costituisce il controller. 
Nella seconda parte verranno disposte le basi implementative che hanno permesso la realizzazione dei controller.
Infine si procederà alla descrizione dei metodi di addestramento e test adoperati, quali dati sono stati raccolti in tali fasi e gli indicatori sfruttati per valutare le performance dei robot virtuali.


